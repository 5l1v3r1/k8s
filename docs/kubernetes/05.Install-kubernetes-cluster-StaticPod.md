[TOC]

1、前面步骤同[kubernetes高可用集群之二进制部署](Install-kubernetes-cluster-Binary.md)，这里不再赘述。

2、所有kube节点安装docker-ce。

## 一、生成kubeconfig

### 1.1、生成kubectl kubeconfig

```
export KUBE_APISERVER="https://apiserver.k8sre.com:6443"
# 设置集群参数
kubectl config set-cluster kubernetes \
  --certificate-authority=ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER}

# 设置客户端认证参数
kubectl config set-credentials admin \
  --client-certificate=admin.pem \
  --client-key=admin.key \
  --embed-certs=true

# 设置上下文参数
kubectl config set-context kubernetes \
  --cluster=kubernetes \
  --user=admin

# 设置默认上下文
kubectl config use-context kubernetes
```



### 1.2、生成kube-controller-manager.kubeconfig

```
export KUBE_APISERVER="https://apiserver.k8sre.com:6443"

# 设置集群参数
kubectl config set-cluster kubernetes \
  --certificate-authority=ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-controller-manager.kubeconfig

# 设置客户端认证参数
kubectl config set-credentials system:kube-controller-manager \
  --client-certificate=kube-controller-manager.pem \
  --client-key=kube-controller-manager.key \
  --embed-certs=true \
  --kubeconfig=kube-controller-manager.kubeconfig

# 设置上下文参数
kubectl config set-context system:kube-controller-manager \
  --cluster=kubernetes \
  --user=system:kube-controller-manager \
  --kubeconfig=kube-controller-manager.kubeconfig

# 设置默认上下文
kubectl config use-context system:kube-controller-manager --kubeconfig=kube-controller-manager.kubeconfig
```



### 1.3、生成kube-scheduler.kubeconfig

```
export KUBE_APISERVER="https://apiserver.k8sre.com:6443"

# 设置集群参数
kubectl config set-cluster kubernetes \
  --certificate-authority=ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-scheduler.kubeconfig

# 设置客户端认证参数
kubectl config set-credentials system:kube-scheduler \
  --client-certificate=kube-scheduler.pem \
  --client-key=kube-scheduler.key \
  --embed-certs=true \
  --kubeconfig=kube-scheduler.kubeconfig

# 设置上下文参数
kubectl config set-context system:kube-scheduler \
  --cluster=kubernetes \
  --user=system:kube-scheduler \
  --kubeconfig=kube-scheduler.kubeconfig

# 设置默认上下文
kubectl config use-context system:kube-scheduler --kubeconfig=kube-scheduler.kubeconfig
```



### 1.4、生成bootstrap.kubeconfig

首先建立一个随机产生`BOOTSTRAP_TOKEN`，并建立`bootstrap`的kubeconfig文件

```
TOKEN_PUB=$(openssl rand -hex 3)
TOKEN_SECRET=$(openssl rand -hex 8)
BOOTSTRAP_TOKEN="${TOKEN_PUB}.${TOKEN_SECRET}"

kubectl -n kube-system create secret generic bootstrap-token-${TOKEN_PUB} \
        --type 'bootstrap.kubernetes.io/token' \
        --from-literal description="cluster bootstrap token" \
        --from-literal token-id=${TOKEN_PUB} \
        --from-literal token-secret=${TOKEN_SECRET} \
        --from-literal usage-bootstrap-authentication=true \
        --from-literal usage-bootstrap-signing=true
```

- Token 必须满足  `[a-z0-9]{6}\.[a-z0-9]{16}` 格式；以  `.` 分割，前面的部分被称作  `Token ID` ，  `Token ID` 并不是 “机密信息”，它可以暴露出去；相对的后面的部分称为  `Token Secret` ，它应该是保密的。

使用以下命令生成bootstrap kubeconfig文件并拷贝至其他node节点

```
export KUBE_APISERVER="https://apiserver.k8sre.com:6443"

# 设置集群参数
kubectl config set-cluster kubernetes \
  --certificate-authority=ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=bootstrap.kubeconfig

# 设置客户端认证参数(${BOOTSTRAP_TOKEN}的值为前面token.csv的值)
kubectl config set-credentials kubelet-bootstrap \
  --token=${BOOTSTRAP_TOKEN} \
  --kubeconfig=bootstrap.kubeconfig

# 设置上下文参数
kubectl config set-context default \
  --cluster=kubernetes \
  --user=kubelet-bootstrap \
  --kubeconfig=bootstrap.kubeconfig

# 设置默认上下文
kubectl config use-context default --kubeconfig=bootstrap.kubeconfig
```

- 向 kubeconfig 写入的是 token，bootstrap 结束后 kube-controller-manager 为 kubelet 创建 client 和 server 证书。



### 1.5、生成kube-proxy.kubeconfig

```
export KUBE_APISERVER="https://apiserver.k8sre.com:6443"

# 设置集群参数
kubectl config set-cluster kubernetes \
  --certificate-authority=ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-proxy.kubeconfig

# 设置客户端认证参数
kubectl config set-credentials kube-proxy \
  --client-certificate=kube-proxy.pem \
  --client-key=kube-proxy.key \
  --embed-certs=true \
  --kubeconfig=kube-proxy.kubeconfig

# 设置上下文参数
kubectl config set-context default \
  --cluster=kubernetes \
  --user=kube-proxy \
  --kubeconfig=kube-proxy.kubeconfig

# 设置默认上下文
kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig
```



### 1.6、分发kubeconfig

```
scp kube-controller-manager.kubeconfig kube-scheduler.kubeconfig ${master_ip}:/etc/kubernetes/
```

```
scp bootstrap.kubeconfig kube-proxy.kubeconfig ${node_ip}:/etc/kubernetes/
```



## 2、部署kubernetes

### 2.1. 安装kubernetes组件

#### 2.1.1.添加kubernetes软件源

/etc/yum.repos.d/kubernetes.repo

```
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
```



#### 2.1.2.安装kube组件

```
yum -y --nogpgcheck install kubelet-1.15.5 kubectl-1.15.5
```

- node节点只安装kubelet即可



### 2.1.3.配置kubectl自动部署

/etc/profile

```
source <(kubectl completion bash)
```



### 2.2、配置kubelet

/etc/kubernetes/kubelet.conf

```
cat > /etc/kubernetes/kubelet.conf << EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
address: 0.0.0.0
cgroupDriver: systemd
cgroupsPerQOS: true
authentication:
  anonymous:
    enabled: false
  webhook:
    enabled: true
    cacheTTL: 2m0s
  x509:
    clientCAFile: "/etc/kubernetes/pki/ca.pem"
authorization:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: 5m0s
    cacheUnauthorizedTTL: 30s
readOnlyPort: 0
port: 10250
clusterDomain: "cluster.local"
clusterDNS:
  - "10.64.0.2"
configMapAndSecretChangeDetectionStrategy: Watch
containerLogMaxFiles: 5
containerLogMaxSize: 10Mi
contentType: application/vnd.kubernetes.protobuf
cpuCFSQuota: true
cpuCFSQuotaPeriod: 100ms
cpuManagerPolicy: none
cpuManagerReconcilePeriod: 10s
enableControllerAttachDetach: true
enableDebuggingHandlers: true
enableContentionProfiling: true
serverTLSBootstrap: true
enforceNodeAllocatable:
- pods
eventBurst: 10
eventRecordQPS: 5
evictionHard:
  imagefs.available: 15%
  memory.available: 100Mi
  nodefs.available: 10%
  nodefs.inodesFree: 5%
evictionPressureTransitionPeriod: 5m0s
failSwapOn: true
fileCheckFrequency: 20s
hairpinMode: promiscuous-bridge
healthzBindAddress: 127.0.0.1
healthzPort: 10248
httpCheckFrequency: 20s
imageGCHighThresholdPercent: 85
imageGCLowThresholdPercent: 80
imageMinimumGCAge: 2m0s
iptablesDropBit: 15
iptablesMasqueradeBit: 14
kubeAPIBurst: 10
kubeAPIQPS: 5
makeIPTablesUtilChains: true
maxOpenFiles: 1000000
maxPods: 110
nodeLeaseDurationSeconds: 40
nodeStatusReportFrequency: 1m0s
nodeStatusUpdateFrequency: 10s
oomScoreAdj: -999
podPidsLimit: -1
registryBurst: 10
registryPullQPS: 5
resolvConf: /etc/resolv.conf
rotateCertificates: true
runtimeRequestTimeout: 2m0s
serializeImagePulls: true
staticPodPath: /etc/kubernetes/manifests
streamingConnectionIdleTimeout: 4h0m0s
syncFrequency: 1m0s
topologyManagerPolicy: none
volumeStatsAggPeriod: 1m0s
EOF
```

```
mkdir -p /usr/lib/systemd/system/kubelet.service.d/
```

/usr/lib/systemd/system/kubelet.service.d/10-kubelet.conf

```
[Service]
Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig --kubeconfig=/etc/kubernetes/kubelet.kubeconfig"
Environment="KUBELET_CONFIG_ARGS=--config=/etc/kubernetes/kubelet.conf"
Environment="KUBELET_ARGS=--hostname-override=172.16.90.204 --cgroup-driver=systemd --network-plugin=cni --pod-infra-container-image=gcr.azk8s.cn/google-containers/pause:3.1 --cert-dir=/etc/kubernetes/pki --root-dir=/var/lib/kubelet --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice"
EnvironmentFile=-/etc/sysconfig/kubelet
ExecStart=
ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_ARGS $KUBELET_EXTRA_ARGS
```



#### 2.3.2、启动服务

```
systemctl daemon-reload
systemctl enable kubelet 
systemctl start kubelet
```



### 2.4、配置kube-apiserver

#### 2.4.1、配置kube-apiserver

```
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-apiserver
    tier: control-plane
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-apiserver
    - --advertise-address=172.16.90.204
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC
    - --client-ca-file=/etc/kubernetes/pki/ca.pem
    - --enable-admission-plugins=NodeRestriction
    - --enable-bootstrap-token-auth=true
    - --etcd-cafile=/etc/kubernetes/pki/etcd-ca.pem
    - --etcd-certfile=/etc/kubernetes/pki/etcd-client.pem
    - --etcd-keyfile=/etc/kubernetes/pki/etcd-client.key
    - --etcd-servers=https://172.16.90.201:2379,https://172.16.90.202:2379,https://172.16.90.203:2379 
    - --insecure-port=0
    - --kubelet-client-certificate=/etc/kubernetes/pki/kube-apiserver-kubelet-client.pem
    - --kubelet-client-key=/etc/kubernetes/pki/kube-apiserver-kubelet-client.key
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --proxy-client-cert-file=/etc/kubernetes/pki/proxy-client.pem
    - --proxy-client-key-file=/etc/kubernetes/pki/proxy-client.key
    - --requestheader-allowed-names=aggregator
    - --requestheader-client-ca-file=/etc/kubernetes/pki/ca.pem
    - --requestheader-extra-headers-prefix=X-Remote-Extra-
    - --requestheader-group-headers=X-Remote-Group
    - --requestheader-username-headers=X-Remote-User
    - --secure-port=6443
    - --service-account-key-file=/etc/kubernetes/pki/ca.key
    - --service-cluster-ip-range=10.64.0.0/16
    - --tls-cert-file=/etc/kubernetes/pki/kube-apiserver.pem
    - --tls-private-key-file=/etc/kubernetes/pki/kube-apiserver.key
    image: gcr.azk8s.cn/google-containers/kube-apiserver:v1.15.5
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 172.16.90.204
        path: /healthz
        port: 6443
        scheme: HTTPS
      initialDelaySeconds: 15
      timeoutSeconds: 15
    name: kube-apiserver
    resources:
      requests:
        cpu: 250m
    volumeMounts:
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
  hostNetwork: true
  priorityClassName: system-cluster-critical
  volumes:
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
status: {}
```



#### 2.4.2、启动服务

```
systemctl restart kubelet
```



### 2.5.配置kube-controller-manager

#### 2.5.1.配置kube-controller-manager

/etc/kubernetes/manifests/kube-controller-manager.yaml

```
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-controller-manager
    tier: control-plane
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-controller-manager
    - --allocate-node-cidrs=true
    - --authentication-kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig
    - --authorization-kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig
    - --bind-address=127.0.0.1
    - --client-ca-file=/etc/kubernetes/pki/ca.pem
    - --cluster-cidr=10.80.0.0/12
    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem
    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
    - --controllers=*,bootstrapsigner,tokencleaner
    - --kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig
    - --leader-elect=true
    - --node-cidr-mask-size=24
    - --requestheader-client-ca-file=/etc/kubernetes/pki/ca.pem
    - --root-ca-file=/etc/kubernetes/pki/ca.pem
    - --service-account-private-key-file=/etc/kubernetes/pki/ca.key
    - --service-cluster-ip-range=10.64.0.0/16
    - --use-service-account-credentials=true
    - --horizontal-pod-autoscaler-sync-period=10s
    image: gcr.azk8s.cn/google-containers/kube-controller-manager:v1.15.5
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10252
        scheme: HTTP
      initialDelaySeconds: 15
      timeoutSeconds: 15
    name: kube-controller-manager
    resources:
      requests:
        cpu: 200m
    volumeMounts:
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    - mountPath: /etc/kubernetes/kube-controller-manager.kubeconfig
      name: kubeconfig
      readOnly: true
  hostNetwork: true
  priorityClassName: system-cluster-critical
  volumes:
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /etc/kubernetes/kube-controller-manager.kubeconfig
      type: FileOrCreate
    name: kubeconfig
status: {}
```



#### 2.5.2.启动kube-controller-manager

```
systemctl daemon-reload
systemctl enable kube-controller-manager
systemctl restart kube-controller-manager
```



### 2.6.安装kube-scheduler

#### 2.6.1、配置kube-scheduler

/etc/kubernetes/manifests/kube-scheduler.yaml

```
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-scheduler
    tier: control-plane
  name: kube-scheduler
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-scheduler
    - --authentication-kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig
    - --authorization-kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig
    - --bind-address=127.0.0.1
    - --kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig
    - --leader-elect=true
    image: gcr.azk8s.cn/google-containers/kube-scheduler:v1.15.5
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10251
        scheme: HTTP
      initialDelaySeconds: 15
      timeoutSeconds: 15
    name: kube-scheduler
    resources:
      requests:
        cpu: 100m
    volumeMounts:
    - mountPath: /etc/kubernetes/kube-scheduler.kubeconfig
      name: kubeconfig
      readOnly: true
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
  hostNetwork: true
  priorityClassName: system-cluster-critical
  volumes:
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /etc/kubernetes/kube-scheduler.kubeconfig
      type: FileOrCreate
    name: kubeconfig
status: {}
```



#### 2.6.2.启动kube-scheduler

```
systemctl daemon-reload
systemctl enable kube-scheduler
systemctl restart kube-scheduler
```



### 2.7.检查集群

```
kubectl get componentstatuses
```

查看当前leader

```
kubectl get endpoints kube-controller-manager -n kube-system -o yaml 
kubectl get endpoints kube-scheduler -n kube-system -o yaml
```



### 2.8、Bootstrap Token Auth 和授予权限

​	kubelet 启动时查找 --kubeletconfig 参数对应的文件是否存在，如果不存在则使用
--bootstrap-kubeconfig 指定的 kubeconfig 文件向 kube-apiserver 发送证书签名
请求 (CSR)。

​	kube-apiserver 收到 CSR 请求后，对其中的 Token 进行认证，认证通过后将请求的 user 设置为 `system:bootstrap:<Token ID>`，group 设置为 `system:bootstrappers`，这一过程称为 Bootstrap Token Auth。

​	默认情况下，这个 user 和 group 没有创建 CSR 的权限，kubelet 启动失败。

​	解决办法是：创建一个 clusterrolebinding，将 group system:bootstrappers 和 clusterrole system:node-bootstrapper 绑定。

```
kubectl create clusterrolebinding kubelet-bootstrap \
        --clusterrole=system:node-bootstrapper \
        --group=system:bootstrappers
```

- kubelet 启动后使用 --bootstrap-kubeconfig 向 kube-apiserver 发送 CSR 请求，当这个 CSR 被 approve 后，kube-controller-manager 为 kubelet 创建 TLS 客户端证书、私钥和 --kubeletconfig 文件。

- 注意：kube-controller-manager 需要配置 `--cluster-signing-cert-file` 和 `--cluster-signing-key-file` 参数，才会为 TLS Bootstrap 创建证书和私钥。



#### 2.8.1.批准kubelet的TLS请求

##### 2.8.1.1.查看未授权的CSR请求

```
# kubectl get csr
NAME        AGE   REQUESTOR                 CONDITION
csr-kqpth   68s   system:bootstrap:af7fd6   Pending
csr-pp879   75s   system:bootstrap:af7fd6   Pending
csr-qmq6z   80s   system:bootstrap:af7fd6   Pending
```

- 当前均处于Pending状态



##### 2.8.1.2.自动approve CSR请求

创建三个 ClusterRoleBinding，分别用于自动 approve client、renew client、renew server 证书

自动批准 system:bootstrappers 组用户 TLS bootstrapping 首次申请证书的 CSR 请求

```
kubectl create clusterrolebinding auto-approve-csrs-for-group --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient --group=system:bootstrappers
```

自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求

```
kubectl create clusterrolebinding node-client-cert-renewal --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient --group=system:nodes
```

创建自动批准相关 CSR 请求的 ClusterRole

```
kubectl create clusterrole approve-node-server-renewal-csr --verb=create --resource=certificatesigningrequests/selfnodeserver --resource-name=certificates.k8s.io
```

自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求

```
kubectl create clusterrolebinding node-server-cert-renewal --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeserver --group=system:nodes
```

查看已有绑定

```
kubectl get clusterrolebindings
```

- auto-approve-csrs-for-group：自动 approve  nodeclient 的第一次 CSR； 注意第一次 CSR 时，请求的 Group 为 system:bootstrappers。
- node-client-cert-renewal：自动 approve selfnodeclient  后续过期的证书，自动生成的证书 Group 为 system:nodes。
- node-server-cert-renewal：自动 approve selfnodeserver 后续过期的证书，自动生成的证书 Group 为 system:nodes。



##### 2.8.1.3.查看kubelet情况

```
# kubectl get csr
NAME        AGE     REQUESTOR                   CONDITION
csr-bx5q2   25s     system:node:172.16.90.205   Pending
csr-kqpth   2m9s    system:bootstrap:af7fd6     Approved,Issued
csr-pk69c   17s     system:node:172.16.90.206   Pending
csr-pp879   2m16s   system:bootstrap:af7fd6     Approved,Issued
csr-qmq6z   2m21s   system:bootstrap:af7fd6     Approved,Issued
csr-s588c   30s     system:node:172.16.90.204   Pending
```

- Pending 的 CSR 用于创建 kubelet server 证书，需要手动 approve

基于安全性考虑，CSR approving controllers 不会自动 approve kubelet server 证书签名请求，需要手动 approve

```
kubectl certificate approve csr-bx5q2 csr-pk69c csr-s588c
```

```
# kubectl get csr
NAME        AGE     REQUESTOR                   CONDITION
csr-bx5q2   2m1s    system:node:172.16.90.205   Approved,Issued
csr-kqpth   3m45s   system:bootstrap:af7fd6     Approved,Issued
csr-pk69c   113s    system:node:172.16.90.206   Approved,Issued
csr-pp879   3m52s   system:bootstrap:af7fd6     Approved,Issued
csr-qmq6z   3m57s   system:bootstrap:af7fd6     Approved,Issued
csr-s588c   2m6s    system:node:172.16.90.204   Approved,Issued
```

kube-controller-manager 已经为各个节点生成了kubelet公私钥和kubeconfig

```
ls -la /etc/kubernetes/kubelet.kubeconfig
ls -l /etc/kubernetes/pki/kubelet*
```



### 2.9、安装kube-proxy

```
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kube-proxy
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: system:kube-proxy
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
subjects:
  - kind: ServiceAccount
    name: kube-proxy
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: system:node-proxier
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app: kube-proxy
  name: kube-proxy
  namespace: kube-system
data:
  kube-proxy.conf: |-
    apiVersion: kubeproxy.config.k8s.io/v1alpha1
    bindAddress: 0.0.0.0
    clientConnection:
      acceptContentTypes: ""
      burst: 10
      contentType: application/vnd.kubernetes.protobuf
      kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig
      qps: 5
    clusterCIDR: 10.80.0.0/12
    configSyncPeriod: 15m0s
    conntrack:
      maxPerCore: 32768
      min: 131072
      tcpCloseWaitTimeout: 1h0m0s
      tcpEstablishedTimeout: 24h0m0s
    enableProfiling: false
    healthzBindAddress: 0.0.0.0:10256
    hostnameOverride: ""
    iptables:
      masqueradeAll: false
      masqueradeBit: 14
      minSyncPeriod: 0s
      syncPeriod: 30s
    ipvs:
      excludeCIDRs: null
      minSyncPeriod: 2s
      scheduler: wlc
      strictARP: false
      syncPeriod: 30s
    kind: KubeProxyConfiguration
    metricsBindAddress: 127.0.0.1:10249
    mode: ipvs
    nodePortAddresses: null
    oomScoreAdj: -999
    portRange: ""
    udpIdleTimeout: 250ms
    winkernel:
      enableDSR: false
      networkName: ""
      sourceVip: ""
  kube-proxy.kubeconfig: |-
    apiVersion: v1
    kind: Config
    clusters:
    - cluster:
        certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        server: https://172.16.90.200:6443
      name: kubernetes
    contexts:
    - context:
        cluster: kubernetes
        user: kube-proxy
      name: default
    current-context: default
    preferences: {}
    users:
    - name: kube-proxy
      user:
        tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    k8s-app: kube-proxy
  name: kube-proxy
  namespace: kube-system
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      k8s-app: kube-proxy
  template:
    metadata:
      creationTimestamp: null
      labels:
        k8s-app: kube-proxy
    spec:
      containers:
      - command:
        - /usr/local/bin/kube-proxy
        - --config=/etc/kubernetes/kube-proxy.conf
        - --hostname-override=$(NODE_NAME)
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
        image: gcr.azk8s.cn/google-containers/kube-proxy:v1.15.5
        imagePullPolicy: IfNotPresent
        name: kube-proxy
        resources: {}
        securityContext:
          privileged: true
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /etc/kubernetes/
          name: kube-proxy
        - mountPath: /run/xtables.lock
          name: xtables-lock
        - mountPath: /lib/modules
          name: lib-modules
          readOnly: true
      dnsPolicy: ClusterFirst
      hostNetwork: true
      nodeSelector:
        beta.kubernetes.io/os: linux
      priorityClassName: system-node-critical
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: kube-proxy
      serviceAccountName: kube-proxy
      terminationGracePeriodSeconds: 30
      tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
      - operator: Exists
      volumes:
      - configMap:
          defaultMode: 420
          name: kube-proxy
        name: kube-proxy
      - hostPath:
          path: /run/xtables.lock
          type: FileOrCreate
        name: xtables-lock
      - hostPath:
          path: /lib/modules
        name: lib-modules
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
```

```
kubectl apply -f kube-proxy.yaml
```



### 2.10.验证服务

#### 2.10.1.检查node是否注册

```
kubectl get nodes
ipvsadm -ln
```

- 此时能看到已注册node节点
- 在Node节点上执行`ipvsadm -ln`可以看到kubernetes的Service IP的规则



### 2.11.集群标签配置

为master节点打污点

```
kubectl taint nodes 172.16.90.204 node-role.kubernetes.io/master=:NoSchedule
kubectl taint nodes 172.16.90.205 node-role.kubernetes.io/master=:NoSchedule
kubectl taint nodes 172.16.90.206 node-role.kubernetes.io/master=:NoSchedule
```

为master节点打role标签

```
kubectl label nodes 172.16.90.204 node-role.kubernetes.io/master=
```

为node节点打role标签

```
kubectl label nodes 172.16.90.207 node-role.kubernetes.io/node=
```


